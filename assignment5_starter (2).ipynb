{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "JOGky0geCXrQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "X8CbU3JHCXrS"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean', feature_weights = None):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.feature_weights = feature_weights if feature_weights is not None else np.ones(11)  # Default is equal weights\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        # TODO: Implement the fit method\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X):\n",
        "        # TODO: Implement the predict method\n",
        "        # Step 1: Get the predicted probabilities\n",
        "        probas = self.predict_proba(X)\n",
        "\n",
        "        # Step 2: Convert probabilities to class predictions\n",
        "        # Class 1 is predicted if the probability of class 1 >= 0.5, else class 0\n",
        "        predictions = np.argmax(probas, axis=1).astype(int)  # Select the class with the highest probability\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        # TODO: Implement distance computation based on self.distance_metric\n",
        "        # Hint: Use numpy operations for efficient computation\n",
        "\n",
        "        # Print the shapes of X1 and X2 to debug\n",
        "        #print(f\"X1 shape: {X1.shape}, X2 shape: {X2.shape}\")\n",
        "\n",
        "        # Ensure X1 and X2 are numpy arrays\n",
        "        X1 = np.array(X1)\n",
        "        X2 = np.array(X2)\n",
        "\n",
        "        # Ensure both X1 and X2 have at least 2 dimensions\n",
        "        if X1.ndim == 1:\n",
        "            X1 = X1.reshape(1, -1)\n",
        "        if X2.ndim == 1:\n",
        "            X2 = X2.reshape(1, -1)\n",
        "\n",
        "        # Debugging: Print the shapes of X1, X2, and feature weights\n",
        "        #print(f\"X1 shape: {X1.shape}, X2 shape: {X2.shape}, Feature weights shape: {self.feature_weights.shape}\")\n",
        "\n",
        "        # Apply feature weights to X1 and X2\n",
        "        X1_weighted = X1 * self.feature_weights\n",
        "        X2_weighted = X2 * self.feature_weights\n",
        "\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X1_weighted[:, np.newaxis] - X2_weighted) ** 2, axis=2))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X1_weighted[:, np.newaxis] - X2_weighted), axis=2)\n",
        "\n",
        "    def predict_proba(self, X_test):\n",
        "        return np.array([self._predict_instance_proba(instance) for instance in X_test])\n",
        "\n",
        "    def _predict_instance(self, instance):\n",
        "        # TODO: Implement instance prediction\n",
        "\n",
        "        # # Calculate distances from this test instance to all training points\n",
        "        # distances = [self._distance(instance, x_train) for x_train in self.X_train]\n",
        "        # # Get the indices of the sorted distances\n",
        "        # nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
        "        # # Get the classes of the K nearest neighbors\n",
        "        # nearest_neighbors = [self.y_train[i] for i in nearest_neighbors_indices]\n",
        "        # # Majority vote\n",
        "        # majority_vote = Counter(nearest_neighbors).most_common(1)[0][0]\n",
        "        # return majority_vote\n",
        "\n",
        "        # Step 1: Compute distances from the test instance to all training points\n",
        "        distances = self.compute_distance(np.array([instance]), self.X_train).flatten()\n",
        "        # Step 2: Find the indices of the k nearest neighbors\n",
        "        nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
        "        # Step 3: Retrieve the labels of the k nearest neighbors\n",
        "        nearest_neighbors_labels = self.y_train[nearest_neighbors_indices]\n",
        "        # Step 4: Perform a majority vote manually\n",
        "        unique_labels, counts = np.unique(nearest_neighbors_labels, return_counts=True)\n",
        "        # Step 5: Return the label with the highest count (the majority class)\n",
        "        return unique_labels[np.argmax(counts)]\n",
        "\n",
        "    def _predict_instance_proba(self, instance):\n",
        "      # Step 1: Compute distances from the instance to all training points\n",
        "      distances = self.compute_distance(np.array([instance]), self.X_train).flatten()\n",
        "\n",
        "      # Step 2: Find the indices of the k nearest neighbors\n",
        "      nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
        "\n",
        "      # Step 3: Get the labels of the k nearest neighbors\n",
        "      nearest_neighbors_labels = self.y_train[nearest_neighbors_indices]\n",
        "\n",
        "      # Step 4: Compute weights based on distances (use 1/(distance + epsilon) to avoid division by zero)\n",
        "      epsilon = 1e-10\n",
        "      nearest_distances = distances[nearest_neighbors_indices]\n",
        "      weights = 1 / (nearest_distances + epsilon)\n",
        "\n",
        "      # Step 5: Calculate the weighted sum for each class\n",
        "      weighted_votes = np.zeros(2)  # Assuming binary classification (class 0 and class 1)\n",
        "      for i, label in enumerate(nearest_neighbors_labels):\n",
        "          label = int(label)\n",
        "          weighted_votes[label] += weights[i]\n",
        "\n",
        "\n",
        "      # Step 6: Normalize the weights to get probabilities\n",
        "      total_weight = np.sum(weights)\n",
        "      prob_class_0 = weighted_votes[0] / total_weight\n",
        "      prob_class_1 = weighted_votes[1] / total_weight\n",
        "\n",
        "      # Step 7: Return the probabilities\n",
        "      return [prob_class_0, prob_class_1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "cr6Pol87CXrS"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # TODO: Implement data preprocessing\n",
        "    # Handle categorical variables, scale features, etc.\n",
        "\n",
        "    # Ensure column names are consistent\n",
        "    train_data.columns = train_data.columns.str.strip().str.lower()\n",
        "    test_data.columns = test_data.columns.str.strip().str.lower()\n",
        "\n",
        "    # Drop irrelevant columns\n",
        "    train_data = train_data.drop(columns=['customerid', 'surname', 'id'], errors='ignore')\n",
        "    test_data = test_data.drop(columns=['customerid', 'surname', 'id'], errors='ignore')\n",
        "\n",
        "    ## Handle missing values (fill with mean for numerical columns)\n",
        "    numerical_cols_train = train_data.select_dtypes(include=np.number).columns\n",
        "    numerical_cols_test = test_data.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Ensure that test_data only uses numerical columns present in both datasets\n",
        "    common_numerical_cols = [col for col in numerical_cols_test if col in numerical_cols_train]\n",
        "\n",
        "    # # Handle missing values (fill with mean for numerical columns)\n",
        "    # train_data.fillna(train_data.mean(), inplace=True)\n",
        "    # test_data.fillna(test_data.mean(), inplace=True)\n",
        "\n",
        "    # One-Hot Encoding for 'Geography'\n",
        "    geography_dummies_train = pd.get_dummies(train_data['geography'], drop_first=True)\n",
        "    geography_dummies_test = pd.get_dummies(test_data['geography'], drop_first=True)\n",
        "\n",
        "    train_data = pd.concat([train_data.drop(columns=['geography']), geography_dummies_train], axis=1)\n",
        "    test_data = pd.concat([test_data.drop(columns=['geography']), geography_dummies_test], axis=1)\n",
        "\n",
        "    # Label Encoding for 'Gender' (Male -> 0, Female -> 1)\n",
        "    train_data['gender'] = train_data['gender'].map({'male': 0, 'female': 1})\n",
        "    test_data['gender'] = test_data['gender'].map({'male': 0, 'female': 1})\n",
        "\n",
        "    # Convert all boolean columns to numeric (int)\n",
        "    bool_cols_train = train_data.select_dtypes(include='bool').columns\n",
        "    bool_cols_test = test_data.select_dtypes(include='bool').columns\n",
        "\n",
        "    train_data[bool_cols_train] = train_data[bool_cols_train].astype(int)\n",
        "    test_data[bool_cols_test] = test_data[bool_cols_test].astype(int)\n",
        "\n",
        "    # Manual Min-Max scaling for numerical columns\n",
        "    #numerical_columns = [col for col in X_train.columns if col not in ['geography', 'gender', 'hascrcard', 'isactivemember']]\n",
        "\n",
        "    for col in common_numerical_cols:\n",
        "        col_min = train_data[col].min()\n",
        "        col_max = train_data[col].max()\n",
        "        #print(\"hello, still works here\")\n",
        "\n",
        "        # Apply scaling for both train and test data\n",
        "        # Check if the column has zero variance to avoid division by zero\n",
        "        if col_max - col_min == 0:\n",
        "            # Handle zero variance columns (e.g., set them to 0)\n",
        "            train_data[col] = 0\n",
        "            test_data[col] = 0\n",
        "        else:\n",
        "            # Apply scaling for both train and test data\n",
        "            train_data[col] = (train_data[col] - col_min) / (col_max - col_min)\n",
        "            test_data[col] = (test_data[col] - col_min) / (col_max - col_min)\n",
        "\n",
        "\n",
        "    # Separate features and labels\n",
        "    X_train = train_data.drop(columns=['exited']).values  # Features for training\n",
        "    y_train = train_data['exited'].values  # Labels for training\n",
        "    X_test = test_data.values  # Features for testing\n",
        "\n",
        "    # After preprocessing data in preprocess_data\n",
        "    print(train_data.dtypes)\n",
        "    print(test_data.dtypes)\n",
        "\n",
        "\n",
        "    return X_train, y_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "f7YBvPurCXrS"
      },
      "outputs": [],
      "source": [
        "def accuracy_score(y_true, y_pred):\n",
        "    correct = sum(y_t == y_p for y_t, y_p in zip(y_true, y_pred))\n",
        "    return correct / len(y_true)\n",
        "\n",
        "#calculate Area Under Curve of ROC curve\n",
        "def calculate_roc_auc(y_true, y_pred_probs):\n",
        "    # Step 1: Sort by predicted probabilities\n",
        "    sorted_indices = np.argsort(y_pred_probs)[::-1]  # Sort in descending order\n",
        "    y_true_sorted = y_true[sorted_indices]\n",
        "    y_pred_probs_sorted = y_pred_probs[sorted_indices]\n",
        "\n",
        "    # Step 2: Initialize values\n",
        "    TPRs = [0]  # True Positive Rates\n",
        "    FPRs = [0]  # False Positive Rates\n",
        "    thresholds = [1]  # Start with a threshold of 1 (all classified as negative)\n",
        "\n",
        "    # Initialize counters\n",
        "    positives = sum(y_true)  # Total number of actual positives (True Positives + False Negatives)\n",
        "    negatives = len(y_true) - positives  # Total number of actual negatives (True Negatives + False Positives)\n",
        "\n",
        "    TP = 0  # True Positives\n",
        "    FP = 0  # False Positives\n",
        "\n",
        "    # Step 3: Loop through sorted predictions and calculate TPR, FPR\n",
        "    for i in range(len(y_true_sorted)):\n",
        "        if y_true_sorted[i] == 1:\n",
        "            TP += 1  # Correctly classified as positive (True Positive)\n",
        "        else:\n",
        "            FP += 1  # Incorrectly classified as positive (False Positive)\n",
        "\n",
        "        # Compute the TPR and FPR for the current threshold\n",
        "        TPR = TP / positives  # True Positive Rate (Recall)\n",
        "        FPR = FP / negatives  # False Positive Rate\n",
        "\n",
        "        TPRs.append(TPR)\n",
        "        FPRs.append(FPR)\n",
        "        thresholds.append(y_pred_probs_sorted[i])\n",
        "\n",
        "    # Step 4: Compute the AUC using the trapezoidal rule\n",
        "    # AUC is the area under the ROC curve\n",
        "    auc = 0.0\n",
        "    for i in range(1, len(TPRs)):\n",
        "        auc += (FPRs[i] - FPRs[i - 1]) * (TPRs[i] + TPRs[i - 1]) / 2  # Trapezoidal area\n",
        "\n",
        "    return np.array(FPRs), np.array(TPRs), auc\n",
        "\n",
        "# Example usage:\n",
        "# y_true = np.array([0, 0, 1, 1])\n",
        "# y_pred_probs = np.array([0.1, 0.4, 0.35, 0.8])\n",
        "\n",
        "# FPRs, TPRs, auc = calculate_roc_auc(y_true, y_pred_probs)\n",
        "# print(f\"FPR: {FPRs}\")\n",
        "# print(f\"TPR: {TPRs}\")\n",
        "# print(f\"AUC: {auc}\")\n",
        "\n",
        "\n",
        "# Define cross-validation function\n",
        "def cross_validate_accuracy(X, y, knn, n_splits=5):\n",
        "    # Shuffle the data to ensure random distribution of folds\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    X_shuffled = X[indices]\n",
        "    y_shuffled = y[indices]\n",
        "\n",
        "    # Split the data into `n_splits` folds\n",
        "    fold_size = len(X) // n_splits\n",
        "    accuracy_scores = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        # Define the validation fold\n",
        "        start = fold * fold_size\n",
        "        end = start + fold_size if fold != n_splits - 1 else len(X)\n",
        "\n",
        "        X_val = X_shuffled[start:end]\n",
        "        y_val = y_shuffled[start:end]\n",
        "\n",
        "        # Use the remaining data as the training set\n",
        "        X_train = np.concatenate([X_shuffled[:start], X_shuffled[end:]], axis=0)\n",
        "        y_train = np.concatenate([y_shuffled[:start], y_shuffled[end:]], axis=0)\n",
        "\n",
        "        # Train the KNN model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the validation set\n",
        "        y_pred = knn.predict(X_val)\n",
        "\n",
        "        # Calculate accuracy for this fold\n",
        "        accuracy = accuracy_score(y_val, y_pred)\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy score across all folds\n",
        "    avg_accuracy = np.mean(accuracy_scores)\n",
        "\n",
        "    return avg_accuracy, accuracy_scores\n",
        "\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    # TODO: Implement cross-validation\n",
        "    # Compute ROC AUC scores\n",
        "\n",
        "    # Step 1: Shuffle the data to ensure random distribution of folds\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    X_shuffled = X[indices]\n",
        "    y_shuffled = y[indices]\n",
        "\n",
        "    # Step 2: Split the data into `n_splits` folds\n",
        "    fold_size = len(X) // n_splits\n",
        "    roc_auc_scores = []\n",
        "\n",
        "    for fold in range(n_splits):\n",
        "        # Define the validation fold\n",
        "        start = fold * fold_size\n",
        "        end = start + fold_size if fold != n_splits - 1 else len(X)\n",
        "\n",
        "        X_val = X_shuffled[start:end]\n",
        "        y_val = y_shuffled[start:end]\n",
        "\n",
        "        # Use the remaining data as the training set\n",
        "        X_train = np.concatenate([X_shuffled[:start], X_shuffled[end:]], axis=0)\n",
        "        y_train = np.concatenate([y_shuffled[:start], y_shuffled[end:]], axis=0)\n",
        "\n",
        "        # Step 3: Train the KNN model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Check the shape of X_val before making predictions\n",
        "        #print(f\"Fold {fold + 1}: X_val shape = {X_val.shape}\")\n",
        "\n",
        "        # Predict probabilities on the validation set\n",
        "        y_pred_probs = knn.predict_proba(X_val)[:, 1]  # Predict probability of class 1\n",
        "\n",
        "        # Compute the ROC AUC score for this fold (only store the AUC value)\n",
        "        _, _, auc = calculate_roc_auc(y_val, y_pred_probs)\n",
        "        roc_auc_scores.append(auc)  # Store only the AUC score\n",
        "\n",
        "    # Compute the average ROC AUC score across all folds\n",
        "    avg_roc_auc = np.mean(roc_auc_scores)\n",
        "\n",
        "    return avg_roc_auc, roc_auc_scores\n",
        "\n",
        "    #     # Step 4: Predict probabilities on the validation set\n",
        "    #     y_pred_probs = knn.predict_proba(X_val)[:, 1]  # Predict probability of class 1\n",
        "\n",
        "    #     # Step 5: Compute the ROC AUC score for this fold\n",
        "    #     roc_auc = calculate_roc_auc(y_val, y_pred_probs)\n",
        "    #     roc_auc_scores.append(roc_auc)\n",
        "\n",
        "    # # Step 6: Compute the average ROC AUC score across all folds\n",
        "    # avg_roc_auc = np.mean(roc_auc_scores)\n",
        "\n",
        "    # return avg_roc_auc, roc_auc_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "QDTmzEK2CXrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856b5719-0319-4827-cb08-c1d2bfe74022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creditscore        float64\n",
            "gender             float64\n",
            "age                float64\n",
            "tenure             float64\n",
            "balance            float64\n",
            "numofproducts      float64\n",
            "hascrcard          float64\n",
            "isactivemember     float64\n",
            "estimatedsalary    float64\n",
            "exited             float64\n",
            "Germany              int64\n",
            "Spain                int64\n",
            "dtype: object\n",
            "creditscore        float64\n",
            "gender             float64\n",
            "age                float64\n",
            "tenure             float64\n",
            "balance            float64\n",
            "numofproducts      float64\n",
            "hascrcard          float64\n",
            "isactivemember     float64\n",
            "estimatedsalary    float64\n",
            "Germany              int64\n",
            "Spain                int64\n",
            "dtype: object\n",
            "k: 10, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 10, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 11, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 11, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 12, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 12, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 13, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 13, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 14, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 14, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 15, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 15, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 16, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 16, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 17, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 17, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 18, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 18, Distance Metric: manhattan, Average Accuracy: 0.7978000000000001\n",
            "k: 19, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 19, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 20, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 20, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 21, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 21, Distance Metric: manhattan, Average Accuracy: 0.7978000000000001\n",
            "k: 22, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 22, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 23, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 23, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 24, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 24, Distance Metric: manhattan, Average Accuracy: 0.7978000000000001\n",
            "k: 25, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 25, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 26, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 26, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 27, Distance Metric: euclidean, Average Accuracy: 0.7978000000000001\n",
            "k: 27, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "k: 28, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 28, Distance Metric: manhattan, Average Accuracy: 0.7978000000000001\n",
            "k: 29, Distance Metric: euclidean, Average Accuracy: 0.7978\n",
            "k: 29, Distance Metric: manhattan, Average Accuracy: 0.7978\n",
            "Best k: 11, Best Distance Metric: euclidean, Best Accuracy: 0.7978000000000001\n"
          ]
        }
      ],
      "source": [
        "# Predict results\n",
        "def save_predictions(knn, X_test, output_file, test_ids):\n",
        "    predictions = knn.predict(X_test)\n",
        "    results = pd.DataFrame({'id': test_ids, 'Exited': predictions})\n",
        "    results.to_csv(output_file, index=False)\n",
        "\n",
        "#creditscore, geography, gender, age, tenure, balance, numproducts, hascrcard, isactivemember, estimatedsalary\n",
        "# Define feature weights manually\n",
        "# Assume 11 features (from your preprocessing step)\n",
        "feature_weights = np.array([5, 1, 1, 3, 5, 5, 3, 5, 5, 5, 1])  # Adjust these weights as needed\n",
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# # Create and evaluate model\n",
        "# knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# # Perform cross-validation\n",
        "# cv_scores = cross_validate(X, y, knn)\n",
        "# print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# average_roc_auc, roc_auc_scores = cross_validate(X, y, knn)\n",
        "# print(f\"Average ROC AUC across folds: {average_roc_auc}\")\n",
        "# print(f\"ROC AUC Scores for each fold: {roc_auc_scores}\")\n",
        "\n",
        "# TODO: hyperparamters tuning\n",
        "\n",
        "# Initialize variables for hyperparameter tuning\n",
        "best_k = None\n",
        "best_distance_metric = None\n",
        "best_acc = 0\n",
        "\n",
        "# Define the range of k values and distance metrics to try\n",
        "k_values = range(10, 30)  # k values to test\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "\n",
        "# TODO: Perform cross-validation and hyperparameter tuning\n",
        "for k in k_values:\n",
        "    for metric in distance_metrics:\n",
        "        # Create a KNN model with the current hyperparameters\n",
        "        knn = KNN(k=k, distance_metric=metric, feature_weights=feature_weights)\n",
        "\n",
        "        # Perform cross-validation to evaluate the model\n",
        "        average_acc, acc_scores = cross_validate_accuracy(X, y, knn, n_splits=5)\n",
        "\n",
        "        #accuracy = accuracy_score(y, knn.predict(X))\n",
        "\n",
        "        # Print the current hyperparameters and ROC AUC score\n",
        "        print(f\"k: {k}, Distance Metric: {metric}, Average Accuracy: {average_acc}\")\n",
        "\n",
        "        # Check if this is the best ROC AUC score so far\n",
        "        if average_acc > best_acc:\n",
        "            best_acc = average_acc\n",
        "            best_k = k\n",
        "            best_distance_metric = metric\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best k: {best_k}, Best Distance Metric: {best_distance_metric}, Best Accuracy: {best_acc}\")\n",
        "\n",
        "# TODO: Train the model on the full dataset with the best hyperparameters\n",
        "knn = KNN(k=best_k, distance_metric=best_distance_metric)\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Make predictions on the test set\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "test_ids = test_data['id']\n",
        "\n",
        "# Save test predictions\n",
        "save_predictions(knn, X_test, 'knn_submission.csv', test_ids)\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}